<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover" />
<title>Blink Squares — Start Fix (blink.html)</title>
<style>
  :root{--bg:#fbfbfb;--muted:#666}
  
html,body{height:100%;margin:0;background:var(--bg);font-family:system-ui,-apple-system,Segoe 
UI,Roboto,Helvetica,Arial;color:#111}
  
.wrap{min-height:100%;display:flex;flex-direction:column;align-items:center;justify-content:center;gap:12px;padding:20px;box-sizing:border-box}
  h1{margin:0;font-size:20px;font-weight:600}
  .squares{display:flex;gap:12px;align-items:center;justify-content:center}
  
.sq{width:92px;height:92px;border-radius:12px;background:#111;display:flex;align-items:center;justify-content:center;color:#fff;font-weight:700;box-shadow:0 
8px 20px rgba(12,12,12,.12);font-size:14px}
  .controls{display:flex;gap:12px;align-items:center;flex-wrap:wrap;justify-content:center}
  #startBtn{padding:12px 
18px;font-size:16px;border-radius:10px;border:0;background:#111;color:#fff;cursor:pointer}
  #status{font-size:13px;color:var(--muted);max-width:720px;text-align:center}
  
#errorBox{font-size:13px;color:#b00020;max-width:720px;text-align:left;white-space:pre-wrap}
  #videoEl{display:none}
  canvas{display:none}
  .note{font-size:13px;color:var(--muted);max-width:640px;text-align:center}
  @media (max-width:420px){ .sq{width:74px;height:74px;font-size:12px} 
#startBtn{font-size:15px} }
  
#debugLog{font-family:monospace;font-size:12px;color:#222;max-width:720px;white-space:pre-wrap;text-align:left}
</style>
</head>
<body>
<div class="wrap">
  <h1>Blink Squares — Left / Right / Both</h1>

  <div class="squares" aria-hidden="true">
    <div id="leftSq" class="sq" aria-label="left">LEFT</div>
    <div id="bothSq" class="sq" aria-label="both">BOTH</div>
    <div id="rightSq" class="sq" aria-label="right">RIGHT</div>
  </div>

  <div class="controls">
    <!-- button intentionally NOT disabled; uses inline handler to ensure click = user 
gesture -->
    <button id="startBtn" onclick="startFlow()">Start camera</button>
    <div id="status">Click Start. If nothing happens check console or the debug log 
below.</div>
  </div>

  <div id="errorBox" aria-live="polite"></div>
  <div id="debugLog"></div>

  <p class="note">Place local libs at: <code>libs/tf.min.js</code>, 
<code>libs/face-landmarks-detection.min.js</code>, <code>libs/mediapipe/face_mesh.js</code>, 
and the wasm files in <code>libs/mediapipe/</code>.</p>

  <video id="videoEl" autoplay playsinline muted></video>
  <canvas id="hiddenCanvas"></canvas>
</div>

<!-- Local libs (must be present in repo) -->
<script src="libs/tf.min.js"></script>
<script src="libs/face-landmarks-detection.min.js"></script>
<script src="libs/mediapipe/face_mesh.js"></script>

<script>
/* Start-fix version:
   - Start button is always active (so click/tap is a direct user gesture).
   - Reports immediate feedback to UI and debug log.
   - Loads model AFTER camera start.
   - Clear, defensive checks for missing scripts.
*/

const statusEl = document.getElementById('status');
const errorBox = document.getElementById('errorBox');
const debugLog = document.getElementById('debugLog');
const leftSq = document.getElementById('leftSq');
const rightSq = document.getElementById('rightSq');
const bothSq = document.getElementById('bothSq');
const videoEl = document.getElementById('videoEl');
const canvas = document.getElementById('hiddenCanvas');

function logDbg(...args){ const s = args.map(a=> (typeof a === 'object' ? JSON.stringify(a) : 
String(a))).join(' '); debugLog.textContent += s + '\n'; console.log(...args); }
function setStatus(s){ statusEl.textContent = s; logDbg('[STATUS]', s); }
function setError(s){ errorBox.textContent = s; logDbg('[ERROR]', s); }

function showEvent(ev){
  const COLORS = { none:'#111', left:'#ff6b6b', right:'#63c2ff', both:'#ffd36b' };
  leftSq.style.background = ev === 'left' ? COLORS.left : COLORS.none;
  rightSq.style.background = ev === 'right' ? COLORS.right : COLORS.none;
  bothSq.style.background = ev === 'both' ? COLORS.both : COLORS.none;
}
showEvent('none');

// state
let model = null;
let running = false;
let closingLeft = false, closingRight = false;
let EAR_THRESHOLD = 0.24;

function bbox(points){ const xs = points.map(p=>p[0]), ys = points.map(p=>p[1]); return 
{minX:Math.min(...xs), maxX:Math.max(...xs), minY:Math.min(...ys), maxY:Math.max(...ys)}; }

async function startFlow(){
  // Immediate UI feedback to confirm button worked
  setError(''); debugLog.textContent = ''; setStatus('Start pressed — checking libraries and 
requesting camera...');

  // quick checks
  if(!window.tf){ setError('ERROR: TensorFlow (tf.min.js) not loaded. Check libs/tf.min.js'); 
return; }
  if(!window.faceLandmarksDetection){ setError('ERROR: face-landmarks-detection not loaded. 
Check libs/face-landmarks-detection.min.js'); return; }
  logDbg('tf', !!window.tf, 'faceLandmarksDetection', !!window.faceLandmarksDetection);

  // Request camera as the user gesture
  try{
    setStatus('Requesting camera (user gesture)…');
    const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user', 
width: { ideal: 640 }, height: { ideal: 480 } }, audio: false });
    videoEl.srcObject = stream;
    await new Promise(r => videoEl.onloadedmetadata = r);
    canvas.width = videoEl.videoWidth || 640; canvas.height = videoEl.videoHeight || 480;
    setStatus('Camera started — now loading model (after camera)...');
  } catch(err){
    setError('Camera error: ' + (err && err.name ? err.name + ' — ' + err.message : 
String(err)));
    return;
  }

  // Load model AFTER camera start
  try{
    if(!window.faceLandmarksDetection){ setError('faceLandmarksDetection not available after 
camera.'); return; }
    // ensure mediapipe assets are looked up in ./libs/mediapipe/
    model = await 
faceLandmarksDetection.load(faceLandmarksDetection.SupportedPackages.mediapipeFacemesh, {
      runtime: 'mediapipe',
      solutionPath: './libs/mediapipe/'
    });
    setStatus('Model loaded — detecting blinks/winks');
  } catch(err){
    setError('Model load failed: ' + (err && err.message ? err.message : String(err)) + 
'\nCheck console for fetch errors (wasm files).');
    console.error(err);
    return;
  }

  // detection loop
  running = true;
  detectLoop();
}

async function detectLoop(){
  setStatus('Detecting — show squares when blink/wink happens');
  while(running){
    try{
      const faces = await model.estimateFaces({ input: videoEl, returnTensors: false, 
flipHorizontal: true });
      if(faces && faces.length){
        const f = faces[0];
        const leftEye = (f.annotations.leftEyeUpper0 || 
[]).concat(f.annotations.leftEyeLower0 || []);
        const rightEye = (f.annotations.rightEyeUpper0 || 
[]).concat(f.annotations.rightEyeLower0 || []);
        if(leftEye.length && rightEye.length){
          const L = bbox(leftEye), R = bbox(rightEye);
          const leftEAR = (L.maxY - L.minY) / (L.maxX - L.minX + 1e-6);
          const rightEAR = (R.maxY - R.minY) / (R.maxX - R.minX + 1e-6);
          const leftClosed = leftEAR < EAR_THRESHOLD;
          const rightClosed = rightEAR < EAR_THRESHOLD;
          if(leftClosed) closingLeft = true;
          if(rightClosed) closingRight = true;
          if(!leftClosed && !rightClosed && (closingLeft || closingRight)){
            let ev = 'both';
            if(closingLeft && !closingRight) ev = 'left';
            else if(closingRight && !closingLeft) ev = 'right';
            showEvent(ev);
            setStatus('Detected: ' + ev.toUpperCase());
            closingLeft = closingRight = false;
          }
        }
      } else {
        // keep last event showing; update status
        setStatus('No face detected — please face the camera');
      }
    } catch(err){
      console.error('Detect error', err);
      setError('Detection error: ' + (err && err.message ? err.message : String(err)));
      // do not crash; try again next frame
    }
    await new Promise(r => requestAnimationFrame(r));
  }
}

// expose helper for debugging in console
window._blinkDemo = {
  startFlow,
  stop: () => { running = false; setStatus('Stopped'); },
  setEAR: v => { EAR_THRESHOLD = Number(v); logDbg('EAR set to', EAR_THRESHOLD); }
};
</script>
</body>
</html>

