<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover" />
<title>Blink Squares — MediaPipe (use your hosted libs)</title>
<style>
  :root{--bg:#fbfbfb;--muted:#666}
  html,body{height:100%;margin:0;background:var(--bg);font-family:system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;color:#111}
  .wrap{min-height:100vh;display:flex;flex-direction:column;align-items:center;justify-content:center;gap:12px;padding:20px;box-sizing:border-box}
  h1{margin:0;font-size:20px;font-weight:600}
  .squares{display:flex;gap:12px;align-items:center;justify-content:center}
  .sq{width:92px;height:92px;border-radius:12px;background:#111;display:flex;align-items:center;justify-content:center;color:#fff;font-weight:700;box-shadow:0 8px 20px rgba(12,12,12,.12);font-size:14px;transition:background-color .14s ease, transform .14s ease}
  .sq.flash{transform:translateY(-6px) scale(1.03); box-shadow:0 18px 34px rgba(12,12,12,.18)}
  .controls{display:flex;gap:12px;align-items:center;flex-wrap:wrap;justify-content:center}
  #startBtn{padding:12px 18px;font-size:16px;border-radius:10px;border:0;background:#111;color:#fff;cursor:pointer}
  /* hide the noisy UI elements (you said you only wanted to see the buttons now) */
  #status, #errorBox, pre#debug, .note { display:none !important; }
  #videoEl{display:none}
  canvas{display:none}
  @media (max-width:420px){ .sq{width:74px;height:74px;font-size:12px} #startBtn{font-size:15px} }
</style>
</head>
<body>
<div class="wrap">
  <h1>Blink Squares — Left / Right / Both</h1>

  <div class="squares" aria-hidden="true">
    <div id="leftSq" class="sq">LEFT</div>
    <div id="bothSq" class="sq">BOTH</div>
    <div id="rightSq" class="sq">RIGHT</div>
  </div>

  <div class="controls">
    <button id="startBtn">Start camera</button>
  </div>

  <div id="errorBox" aria-live="polite"></div>
  <pre id="debug"></pre>

  <video id="videoEl" autoplay playsinline muted></video>
  <canvas id="hiddenCanvas"></canvas>
</div>

<script>
/* Updated:
   - flashes appropriate box briefly (left, right, or both)
   - removed noisy on-page logging and hidden status/debug UI
   - still attempts to load your /libs/face_mesh.js and wasm files
*/

const startBtn = document.getElementById('startBtn');
const errorBox = document.getElementById('errorBox');
const leftSq = document.getElementById('leftSq');
const rightSq = document.getElementById('rightSq');
const bothSq = document.getElementById('bothSq');
const videoEl = document.getElementById('videoEl');

// NO-OP status/error handlers (UI for them is hidden)
function setStatus(_) {}
function setError(_) { /* intentionally empty */ }

// Flash helper
const COLORS = { none:'#111', left:'#ff6b6b', right:'#63c2ff', both:'#ffd36b' };
const flashTimeouts = new WeakMap();
function flashElement(el, color, ms = 260){
  if(!el) return;
  // clear existing timeout
  const prevT = flashTimeouts.get(el);
  if(prevT) clearTimeout(prevT);
  // apply
  el.style.background = color;
  el.classList.add('flash');
  const t = setTimeout(() => {
    el.style.background = ''; // revert to CSS default
    el.classList.remove('flash');
    flashTimeouts.delete(el);
  }, ms);
  flashTimeouts.set(el, t);
}

function showEvent(ev){
  if(ev === 'left')      flashElement(leftSq, COLORS.left);
  else if(ev === 'right') flashElement(rightSq, COLORS.right);
  else if(ev === 'both')  flashElement(bothSq, COLORS.both);
}

// MediaPipe FaceMesh canonical eye indices
const LEFT_EYE_INDICES  = [33,160,158,133,153,144];
const RIGHT_EYE_INDICES = [362,385,387,263,373,380];

function toPoint(p){ if(Array.isArray(p)) return {x:p[0], y:p[1]}; if(p==null) return {x:0,y:0}; return {x:p.x, y:p.y}; }
function dist(a,b){ const dx=a.x-b.x, dy=a.y-b.y; return Math.hypot(dx,dy); }
function computeEAR(landmarks, idxs){
  const p1 = toPoint(landmarks[idxs[0]]), p2 = toPoint(landmarks[idxs[1]]), p3 = toPoint(landmarks[idxs[2]]),
        p4 = toPoint(landmarks[idxs[3]]), p5 = toPoint(landmarks[idxs[4]]), p6 = toPoint(landmarks[idxs[5]]);
  const A = dist(p2,p6), B = dist(p3,p5), C = dist(p1,p4) || 1e-6;
  return (A + B) / (2 * C);
}

// locateFile mapper: maps requested asset filenames to your hosted wasm files
function locateFileMapper(file){
  const lname = String(file).toLowerCase();
  if(lname.includes('simd') && lname.includes('.wasm')) {
    return '/libs/mediapipe/face_mesh_solution_simd_wasm_bin.wasm';
  }
  if(lname.includes('.wasm')) {
    return '/libs/mediapipe/face_mesh_solution_wasm_bin.wasm';
  }
  return '/libs/mediapipe/' + file;
}

// main flow
let faceMeshInstance = null;
let running = false;
let closingLeft = false, closingRight = false;
let EAR_THRESHOLD = 0.18;

// Try to find/load FaceMesh (UMD script or dynamic import ESM)
async function ensureFaceMeshClass(){
  setStatus('loading');
  // try script tag load first
  try{
    if(window.FaceMesh && typeof window.FaceMesh === 'function') return window.FaceMesh;
    const existing = document.querySelector('script[data-our-facemesh]');
    if(!existing){
      await new Promise((resolve, reject) => {
        const s = document.createElement('script');
        s.src = '/libs/face_mesh.js';
        s.async = true;
        s.setAttribute('data-our-facemesh','1');
        s.onload = () => resolve();
        s.onerror = () => reject(new Error('script load failed'));
        document.head.appendChild(s);
      });
      if(window.FaceMesh && typeof window.FaceMesh === 'function') return window.FaceMesh;
    } else {
      // existing script present but no global yet -> fall through to import attempt
    }
  } catch(e){
    // fall through to dynamic import
  }

  // dynamic import (ESM)
  try{
    const mod = await import('/libs/face_mesh.js');
    const candidates = [mod.default, mod.FaceMesh, mod.MPFaceMesh, mod.FaceMeshModule];
    for(const c of candidates) if(typeof c === 'function') return c;
    if(typeof mod === 'function') return mod;
    throw new Error('No FaceMesh export found in module');
  } catch(err){
    throw new Error('Could not load FaceMesh class from /libs/face_mesh.js. Ensure file and wasm files are at /libs/mediapipe/');
  }
}

async function initFaceMesh(ClassFaceMesh){
  setStatus('init');
  faceMeshInstance = new ClassFaceMesh({ locateFile: (file) => locateFileMapper(file) });
  faceMeshInstance.setOptions({
    maxNumFaces: 1,
    refineLandmarks: true,
    minDetectionConfidence: 0.5,
    minTrackingConfidence: 0.5
  });
  faceMeshInstance.onResults(onFaceMeshResults);
}

function onFaceMeshResults(results){
  if(!results || !results.multiFaceLandmarks || results.multiFaceLandmarks.length === 0){
    // no face visible
    return;
  }
  const lm = results.multiFaceLandmarks[0];
  processLandmarks(lm);
}

function processLandmarks(landmarks){
  try{
    const leftEAR = computeEAR(landmarks, LEFT_EYE_INDICES);
    const rightEAR = computeEAR(landmarks, RIGHT_EYE_INDICES);
    const leftClosed = leftEAR < EAR_THRESHOLD;
    const rightClosed = rightEAR < EAR_THRESHOLD;
    if(leftClosed) closingLeft = true;
    if(rightClosed) closingRight = true;
    if(!leftClosed && !rightClosed && (closingLeft || closingRight)){
      let ev = 'both';
      if(closingLeft && !closingRight) ev = 'left';
      else if(closingRight && !closingLeft) ev = 'right';
      showEvent(ev); // flash the appropriate box
      closingLeft = closingRight = false;
    } else {
      // ongoing EAR monitoring (no visible UI updates; debug hidden)
    }
  } catch(e){
    // swallow; console only for hard errors
    console.error('processLandmarks error', e);
  }
}

async function detectLoop(){
  running = true;
  try{
    while(running){
      if(videoEl.readyState >= 2 && faceMeshInstance){
        try{
          await faceMeshInstance.send({image: videoEl});
        } catch(e){
          setError('FaceMesh runtime send() error. Check wasm files.');
          running = false;
          break;
        }
      }
      await new Promise(r => requestAnimationFrame(r));
    }
  } catch(err){
    setError('Detection loop error.');
  }
}

// Start button handler
startBtn.addEventListener('click', async () => {
  startBtn.disabled = true;
  setError('');
  setStatus('starting');

  // Request camera on user gesture
  try{
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: 'user', width: { ideal: 640 }, height: { ideal: 480 } },
      audio: false
    });
    videoEl.srcObject = stream;
    await new Promise(r => (videoEl.onloadedmetadata = r));
  } catch(err){
    setError('Camera error');
    startBtn.disabled = false;
    return;
  }

  // Load face_mesh.js (your file at /libs/face_mesh.js) and locate FaceMesh class
  let FaceMeshClass = null;
  try{
    FaceMeshClass = await ensureFaceMeshClass();
    if(!FaceMeshClass) throw new Error('FaceMesh class not found after loading');
  } catch(err){
    setError('FaceMesh load error');
    startBtn.disabled = false;
    return;
  }

  // Initialize instance and start loop
  try{
    await initFaceMesh(FaceMeshClass);
    await detectLoop();
  } catch(err){
    setError('Initialization failed');
    startBtn.disabled = false;
    return;
  }
});

// expose minimal debug helpers (no noisy logging)
window._blink = {
  stop: () => { running = false; setStatus('stopped'); },
  EAR: (v) => { EAR_THRESHOLD = Number(v); }
};
</script>
</body>
</html>
