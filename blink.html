<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover" />
<title>Blink Squares — Left / Right / Both</title>
<style>
  :root{--bg:#fafafa;--card:#111;--muted:#666}
  html,body{height:100%;margin:0;background:var(--bg);font-family:system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial}
  .wrap{min-height:100%;display:flex;flex-direction:column;align-items:center;justify-content:center;gap:18px;padding:20px;box-sizing:border-box}
  h1{margin:0;font-size:20px;font-weight:600;color:#111}
  .squares{display:flex;gap:12px;align-items:center;justify-content:center}
  .sq{width:92px;height:92px;border-radius:12px;background:#111;display:flex;align-items:center;justify-content:center;color:white;font-weight:700;box-shadow:0 8px 20px rgba(12,12,12,.12);font-size:14px}
  .controls{display:flex;gap:12px;align-items:center;flex-wrap:wrap;justify-content:center}
  #startBtn{padding:12px 16px;font-size:16px;border-radius:10px;border:0;background:#111;color:#fff;cursor:pointer}
  #status{font-size:13px;color:var(--muted);max-width:640px;text-align:center}
  #videoEl{display:none;width:320px;height:240px}
  canvas{display:none}
  .note{font-size:13px;color:var(--muted);max-width:560px;text-align:center}
  @media (max-width:420px){
    .sq{width:74px;height:74px;font-size:12px;border-radius:10px}
    #startBtn{font-size:15px;padding:10px 14px}
  }
</style>
</head>
<body>
<div class="wrap">
  <h1>Blink Squares — Left / Right / Both</h1>

  <div class="squares" aria-hidden="true">
    <div id="leftSq" class="sq">LEFT</div>
    <div id="bothSq" class="sq">BOTH</div>
    <div id="rightSq" class="sq">RIGHT</div>
  </div>

  <div class="controls">
    <button id="startBtn">Start camera</button>
    <div id="status">Press Start, allow camera. Good frontal lighting improves reliability.</div>
  </div>

  <p class="note">This runs fully in your browser (no uploads). The square lights up for the last detected event and remains until the next event. Works on mobile — if camera doesn't appear try switching browser or the other camera.</p>

  <!-- Hidden video + canvas -->
  <video id="videoEl" autoplay playsinline muted></video>
  <canvas id="hiddenCanvas"></canvas>
</div>

<!-- TF.js + MediaPipe facemesh (face-landmarks-detection) -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@1.0.3/dist/face-landmarks-detection.min.js"></script>

<script>
(async function(){
  const startBtn = document.getElementById('startBtn');
  const status = document.getElementById('status');
  const videoEl = document.getElementById('videoEl');
  const canvas = document.getElementById('hiddenCanvas');
  const leftSq = document.getElementById('leftSq');
  const rightSq = document.getElementById('rightSq');
  const bothSq = document.getElementById('bothSq');

  const COLORS = { none:'#111', left:'#ff6b6b', right:'#63c2ff', both:'#ffd36b' };
  function showEvent(ev){
    leftSq.style.background = ev === 'left' ? COLORS.left : COLORS.none;
    rightSq.style.background = ev === 'right' ? COLORS.right : COLORS.none;
    bothSq.style.background = ev === 'both' ? COLORS.both : COLORS.none;
  }
  showEvent('none');

  // detection parameters (tweak if needed)
  const EAR_THRESHOLD = 0.24; // typical 0.18-0.28 (lower = less sensitive)
  // State flags
  let closingLeft = false, closingRight = false;
  let model = null;
  let running = false;
  let lastEvent = 'none';

  // small bbox helper
  function bbox(points){
    const xs = points.map(p=>p[0]), ys = points.map(p=>p[1]);
    return {minX:Math.min(...xs), maxX:Math.max(...xs), minY:Math.min(...ys), maxY:Math.max(...ys)};
  }

  // Start sequence: get camera first, then load model (safer on mobile)
  startBtn.addEventListener('click', async ()=>{
    startBtn.disabled = true;
    status.textContent = 'Requesting camera...';
    try{
      // request camera (front-facing preferred). If you want rear camera use facingMode: { exact: "environment" }
      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user', width: { ideal: 640 }, height: { ideal: 480 } }, audio: false });
      videoEl.srcObject = stream;
      await new Promise(r => videoEl.onloadedmetadata = r);
      // size canvas
      canvas.width = videoEl.videoWidth || 640;
      canvas.height = videoEl.videoHeight || 480;

      status.textContent = 'Camera started. Loading model (this can take a few seconds)...';
      // load model after camera start to avoid some mobile permission issues
      model = await faceLandmarksDetection.load(faceLandmarksDetection.SupportedPackages.mediapipeFacemesh);
      status.textContent = 'Model loaded — detecting blinks/winks';
      running = true;
      detectLoop();
    } catch(err){
      console.error('Startup error:', err);
      status.textContent = 'Could not start camera. Check permissions or try another browser (Chrome/Edge recommended).';
      startBtn.disabled = false;
    }
  });

  async function detectLoop(){
    const ctx = canvas.getContext('2d');
    while(running){
      try{
        // estimate faces (single face)
        const faces = await model.estimateFaces({input: videoEl, returnTensors: false, flipHorizontal: true});
        if(faces && faces.length){
          const f = faces[0];
          // gather eye points
          const leftEye = (f.annotations.leftEyeUpper0 || []).concat(f.annotations.leftEyeLower0 || []);
          const rightEye = (f.annotations.rightEyeUpper0 || []).concat(f.annotations.rightEyeLower0 || []);
          if(leftEye.length && rightEye.length){
            const L = bbox(leftEye), R = bbox(rightEye);
            const leftEAR = (L.maxY - L.minY) / (L.maxX - L.minX + 1e-6);
            const rightEAR = (R.maxY - R.minY) / (R.maxX - R.minX + 1e-6);
            const leftClosed = leftEAR < EAR_THRESHOLD;
            const rightClosed = rightEAR < EAR_THRESHOLD;

            // accumulate closing flags while eyes are down
            if(leftClosed) closingLeft = true;
            if(rightClosed) closingRight = true;

            // when both are open again after any closing, produce event
            if(!leftClosed && !rightClosed && (closingLeft || closingRight)){
              if(closingLeft && closingRight){
                lastEvent = 'both';
              } else if(closingLeft){
                lastEvent = 'left';
              } else if(closingRight){
                lastEvent = 'right';
              } else {
                lastEvent = 'both';
              }
              showEvent(lastEvent);
              status.textContent = `Detected: ${lastEvent.toUpperCase()}`;
              // reset
              closingLeft = closingRight = false;
            }
            // small UI hint while closed (optional)
            // else keep lastEvent visible until next.
          }
        } else {
          // no face: do not change lastEvent, but update status
          status.textContent = 'No face detected — position camera facing you';
        }
      } catch(err){
        console.error('Detection error:', err);
        status.textContent = 'Detection error — check console';
      }
      await new Promise(r => requestAnimationFrame(r));
    }
  }

  // expose for debugging from console
  window._blinkDemo = { setThreshold: v => { EAR_THRESHOLD = v; } };

})();
</script>
</body>
</html>